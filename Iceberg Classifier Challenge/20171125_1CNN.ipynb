{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from skimage import io,transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_json(r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\data/train.json')\n",
    "#pred_df=pd.read_json(r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\data/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the raw data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df,val_df=train_test_split(train_df,test_size=0.4,random_state=9,shuffle=True,stratify=train_df['is_iceberg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>[-22.52327, -20.36145, -18.631905, -19.001574,...</td>\n",
       "      <td>[-26.236002, -27.819691, -25.408276, -25.14897...</td>\n",
       "      <td>6706ea46</td>\n",
       "      <td>36.1091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>[-24.873583, -23.380947, -23.155365, -24.60641...</td>\n",
       "      <td>[-24.873583, -24.34704, -25.434231, -26.033535...</td>\n",
       "      <td>32b4a247</td>\n",
       "      <td>45.2814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>[-28.554342, -26.37149, -25.17157, -25.171608,...</td>\n",
       "      <td>[-26.055567, -27.394543, -28.55442, -30.389864...</td>\n",
       "      <td>d86deb2b</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "135   [-22.52327, -20.36145, -18.631905, -19.001574,...   \n",
       "425   [-24.873583, -23.380947, -23.155365, -24.60641...   \n",
       "1593  [-28.554342, -26.37149, -25.17157, -25.171608,...   \n",
       "\n",
       "                                                 band_2        id inc_angle  \\\n",
       "135   [-26.236002, -27.819691, -25.408276, -25.14897...  6706ea46   36.1091   \n",
       "425   [-24.873583, -24.34704, -25.434231, -26.033535...  32b4a247   45.2814   \n",
       "1593  [-26.055567, -27.394543, -28.55442, -30.389864...  d86deb2b        na   \n",
       "\n",
       "      is_iceberg  \n",
       "135            1  \n",
       "425            1  \n",
       "1593           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_minibatch(inputs=None,batch_size=128,shuffle=True):\n",
    "    data_cnt=inputs.shape[0]\n",
    "    if batch_size>data_cnt:\n",
    "        raise('batch bigger than data nmber')\n",
    "    if shuffle:\n",
    "        df=inputs.sample(data_cnt)\n",
    "    else:\n",
    "        df=inputs\n",
    "    start_idx=0\n",
    "    end_idx=batch_size\n",
    "    while True:\n",
    "        if end_idx<start_idx:\n",
    "            batch_df=df.iloc[start_idx:].append(df.iloc[:end_idx])\n",
    "        else:\n",
    "            batch_df=df.iloc[start_idx:end_idx]\n",
    "        start_idx=(start_idx+batch_size)%data_cnt\n",
    "        end_idx=(start_idx+batch_size)%data_cnt\n",
    "        band1=np.array([x for x in batch_df['band_1']])\n",
    "        band2=np.array([x for x in batch_df['band_2']])\n",
    "        imgs=np.stack([band1.reshape(-1,75,75),band2.reshape(-1,75,75)],axis=-1)\n",
    "        imgs=imgs.astype(np.float32)\n",
    "        labels=batch_df['is_iceberg'].astype(np.int8).values\n",
    "        yield imgs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img,train_label=next(generate_minibatch(inputs=train_df,batch_size=train_df.shape[0]))\n",
    "test_img,test_label=next(generate_minibatch(inputs=val_df,batch_size=val_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor,keep_prob,regularizer):\n",
    "    with tf.variable_scope('layer1-conv1') as scope:\n",
    "        conv1_weights=tf.get_variable(name='weight',shape=[3,3,2,64],initializer=tf.random_normal_initializer(stddev=0.01,mean=0,seed=9))\n",
    "        conv1_biases=tf.get_variable(name='bias',shape=[64],initializer=tf.constant_initializer(0.01))\n",
    "        conv1=tf.nn.conv2d(input_tensor,conv1_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu1=tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))\n",
    "        tf.summary.histogram('layer1-conv1-w',conv1_weights)\n",
    "        tf.summary.histogram('layer1-conv1-b',conv1_biases)\n",
    "    with tf.name_scope('layer2-pool1'):\n",
    "        pool1=tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "        \n",
    "    with tf.variable_scope('layer3-conv2'):\n",
    "        conv2_weights=tf.get_variable(name='weight',shape=[5,5,64,64],initializer=tf.truncated_normal_initializer(stddev=0.01,mean=0.0,seed=9))\n",
    "        conv2_biases=tf.get_variable(name='bias',shape=64,initializer=tf.constant_initializer(0.01))\n",
    "        conv2=tf.nn.conv2d(pool1,conv2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu2=tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))\n",
    "    with tf.name_scope('layer4-pool2'):\n",
    "        pool2=tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "        \n",
    "    with tf.variable_scope('layer5-conv3'):\n",
    "        conv3_weights=tf.get_variable('weight',shape=[3,3,64,32],initializer=tf.truncated_normal_initializer(stddev=0.01,mean=0.0,seed=9))\n",
    "        conv3_biases=tf.get_variable('bias',shape=[32],initializer=tf.constant_initializer(0.0))\n",
    "        conv3=tf.nn.conv2d(pool2,conv3_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu3=tf.nn.relu(tf.nn.bias_add(conv3,conv3_biases))\n",
    "    with tf.name_scope('layer6-pool3'):\n",
    "        pool3=tf.nn.max_pool(relu3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "    \n",
    "    with tf.variable_scope('layer7-conv4'):\n",
    "        conv4_weights=tf.get_variable(name='weight',shape=[3,3,32,64],initializer=tf.truncated_normal_initializer(stddev=0.01,mean=0.0,seed=9))\n",
    "        conv4_biases=tf.get_variable(name='bias',shape=[64],initializer=tf.constant_initializer(0.01))\n",
    "        conv4=tf.nn.conv2d(pool3,conv4_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu4=tf.nn.relu(tf.nn.bias_add(conv4,conv4_biases))\n",
    "    with tf.name_scope('layer8-pool4'):\n",
    "        pool4=tf.nn.max_pool(relu4,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "        nodes=4*4*64\n",
    "        flatened=tf.reshape(pool4,[-1,nodes])\n",
    "    \n",
    "    with tf.variable_scope('layer9-fc1'):\n",
    "        fc1_weights=tf.get_variable(name='weight',shape=[nodes,1024],initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        if regularizer!=None:\n",
    "            tf.add_to_collection('losses',regularizer(fc1_weights))\n",
    "        fc1_biases=tf.get_variable(name='bias',shape=[1024],initializer=tf.constant_initializer(0.01))\n",
    "        fc1=tf.nn.relu(tf.matmul(flatened,fc1_weights)+fc1_biases)\n",
    "        fc1=tf.nn.dropout(fc1,keep_prob)\n",
    "    \n",
    "    with tf.variable_scope('layer10-fc2'):\n",
    "        fc2_weights=tf.get_variable(name='weight',shape=[1024,512],initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        if regularizer!=None:\n",
    "            tf.add_to_collection('losses',regularizer(fc2_weights))\n",
    "        fc2_biases=tf.get_variable(name='bias',shape=[512],initializer=tf.constant_initializer(0.01))\n",
    "        fc2=tf.nn.relu(tf.matmul(fc1,fc2_weights)+fc2_biases)\n",
    "        fc2=tf.nn.dropout(fc2,keep_prob)\n",
    "    \n",
    "    with tf.variable_scope('layer11-fc3'):\n",
    "        fc3_weights=tf.get_variable(name='weight',shape=[512,2],initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        if regularizer!=None:\n",
    "            tf.add_to_collection('losses',regularizer(fc3_weights))\n",
    "        fc3_biases=tf.get_variable(name='bias',shape=[2],initializer=tf.constant_initializer(0.01))\n",
    "        logit=tf.matmul(fc2,fc3_weights)+fc3_biases\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_h=75\n",
    "img_w=75\n",
    "img_c=2\n",
    "n_steps=400\n",
    "batch_size=128\n",
    "model_path=r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\model\\cnn_model/cnn.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_graph=tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with conv_graph.as_default():\n",
    "    x=tf.placeholder(shape=[None,img_w,img_h,img_c],dtype=tf.float32,name='input_imgs')\n",
    "    y=tf.placeholder(shape=[None],dtype=tf.int32,name='input_labels')\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    regularizer=tf.contrib.layers.l2_regularizer(0.0001)\n",
    "    logits=inference(x,keep_prob,regularizer)\n",
    "    regu_loss=tf.reduce_sum(tf.get_collection('losses'))\n",
    "    loss=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y))\n",
    "    total_loss=loss+regu_loss\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(total_loss)\n",
    "    saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.692982 ;  test_loss: 0.692975\n",
      "train_loss: 0.641184 ;  test_loss: 0.637685\n",
      "train_loss: 0.558514 ;  test_loss: 0.565213\n",
      "train_loss: 0.545457 ;  test_loss: 0.555825\n",
      "train_loss: 0.540922 ;  test_loss: 0.550939\n",
      "train_loss: 0.525789 ;  test_loss: 0.570677\n",
      "train_loss: 0.51272 ;  test_loss: 0.522989\n",
      "train_loss: 0.847079 ;  test_loss: 0.851597\n",
      "train_loss: 0.493065 ;  test_loss: 0.529151\n",
      "train_loss: 0.405668 ;  test_loss: 0.463972\n",
      "train_loss: 0.334774 ;  test_loss: 0.40449\n",
      "train_loss: 0.325349 ;  test_loss: 0.388571\n",
      "train_loss: 0.330824 ;  test_loss: 0.388075\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=conv_graph) as sess:\n",
    "    summary_merge=tf.summary.merge_all()\n",
    "    train_writer=tf.summary.FileWriter(r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\model\\cnn_info_view/batch128/train/',sess.graph)\n",
    "    test_writer=tf.summary.FileWriter(r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\model\\cnn_info_view/batch128/test/',sess.graph)\n",
    "    start_time=time.clock()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_loss=0.0\n",
    "    i=0\n",
    "    for img,label in generate_minibatch(train_df,batch_size):\n",
    "        sess.run(train_op,feed_dict={x:img,y:label,keep_prob:0.5})\n",
    "        #write summary info into logs\n",
    "        if i%10==0:\n",
    "            train_infos=sess.run(summary_merge,feed_dict={x:train_img,y:train_label,keep_prob:1.0})\n",
    "            test_infos=sess.run(summary_merge,feed_dict={x:test_img,y:test_label,keep_prob:1.0})\n",
    "            train_writer.add_summary(train_infos,i)\n",
    "            test_writer.add_summary(test_infos,i)\n",
    "        if i%20==0:\n",
    "            train_loss=sess.run(loss,feed_dict={x:train_img,y:train_label,keep_prob:1.0})\n",
    "            test_loss=sess.run(loss,feed_dict={x:test_img,y:test_label,keep_prob:1.0})\n",
    "            print('train_loss:',train_loss,';  test_loss:',test_loss)\n",
    "        i+=1\n",
    "        if i>n_steps:\n",
    "            break\n",
    "    end_time=time.clock()\n",
    "    print('Time:',end_time-start_time)\n",
    "    saver.save(sess,model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir=r\"F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\model\\cnn_model/\"\n",
    "pred_data_path=r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\data/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(data_path,batch_size=100):\n",
    "    with open(data_path) as file:\n",
    "        lines=file.readlines()\n",
    "    pred_df=pd.DataFrame(json.loads(lines[0]))\n",
    "    # 将数据转换成模型需要的格式\n",
    "    pred_band1=np.array([x for x in pred_df['band_1']])\n",
    "    pred_band2=np.array([x for x in pred_df['band_2']])\n",
    "    pred_imgs=np.stack([pred_band1.reshape(-1,75,75),pred_band2.reshape(-1,75,75)],axis=-1)\n",
    "    pred_imgs=pred_imgs.astype(np.float32)\n",
    "    img_id=pred_df[['id']]\n",
    "    img_cnt=pred_imgs.shape[0]\n",
    "    i=0\n",
    "    while i<img_cnt:\n",
    "        end_idx=min(i+batch_size,img_cnt)\n",
    "        yield pred_imgs[i:end_idx],img_id.iloc[i:end_idx]\n",
    "        i=i+batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\model\\cnn_model/cnn.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:0x200\n",
      "predict:1x200\n",
      "predict:2x200\n",
      "predict:3x200\n",
      "predict:4x200\n",
      "predict:5x200\n",
      "predict:6x200\n",
      "predict:7x200\n",
      "predict:8x200\n",
      "predict:9x200\n",
      "predict:10x200\n",
      "predict:11x200\n",
      "predict:12x200\n",
      "predict:13x200\n",
      "predict:14x200\n",
      "predict:15x200\n",
      "predict:16x200\n",
      "predict:17x200\n",
      "predict:18x200\n",
      "predict:19x200\n",
      "predict:20x200\n",
      "predict:21x200\n",
      "predict:22x200\n",
      "predict:23x200\n",
      "predict:24x200\n",
      "predict:25x200\n",
      "predict:26x200\n",
      "predict:27x200\n",
      "predict:28x200\n",
      "predict:29x200\n",
      "predict:30x200\n",
      "predict:31x200\n",
      "predict:32x200\n",
      "predict:33x200\n",
      "predict:34x200\n",
      "predict:35x200\n",
      "predict:36x200\n",
      "predict:37x200\n",
      "predict:38x200\n",
      "predict:39x200\n",
      "predict:40x200\n",
      "predict:41x200\n",
      "predict:42x200\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(model_dir+\"cnn.ckpt.meta\")\n",
    "    saver.restore(sess, model_dir+\"cnn.ckpt\")\n",
    "    graph=tf.get_default_graph()\n",
    "    x=graph.get_tensor_by_name(\"input_imgs:0\")\n",
    "    keep_prob=graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    logits=graph.get_tensor_by_name('layer11-fc3/add:0')\n",
    "    probs=tf.nn.softmax(logits)\n",
    "    pred_probs=[]\n",
    "    k=0\n",
    "    batch_test=200\n",
    "    for pred_imgs,img_id in prepare_data(pred_data_path,batch_size=batch_test):\n",
    "        result=sess.run(probs,feed_dict={x:pred_imgs,keep_prob:1.0})\n",
    "        pred_prob=result[:,1]\n",
    "        img_id['is_iceberg']=pred_prob\n",
    "        pred_probs.append(img_id)\n",
    "        print('predict:{0}x{1}'.format(k,batch_test))\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_result=pred_probs[0]\n",
    "for i in range(1,len(pred_probs)):\n",
    "    pred_result=pred_result.append(pred_probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5941774d</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4023181e</td>\n",
       "      <td>0.742121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b20200e4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7f018bb</td>\n",
       "      <td>0.960401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371c8c3</td>\n",
       "      <td>0.770937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  5941774d    0.000836\n",
       "1  4023181e    0.742121\n",
       "2  b20200e4    1.000000\n",
       "3  e7f018bb    0.960401\n",
       "4  4371c8c3    0.770937"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_result.to_csv(r'F:\\study\\competitions\\Iceberg-Classifier\\Iceberg Classifier Challenge\\20171125_1CNN_pred1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
